{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 backpropagation\n",
      "[[0.08238065]\n",
      " [0.99190686]]\n",
      "[[0.08238065 0.99190686]\n",
      " [0.08238065 0.99190686]\n",
      " [0.08238065 0.99190686]]\n",
      "A shape: (3, 1)\n",
      "gradient shape: (3, 1)\n",
      "(3, 2)\n",
      "(1, 2)\n",
      "Layer 0 backpropagation\n",
      "[[ 0.20363658]\n",
      " [-0.12446946]\n",
      " [-0.12119262]]\n",
      "[[ 0.20363658 -0.12446946 -0.12119262]\n",
      " [ 0.20363658 -0.12446946 -0.12119262]]\n",
      "A shape: (2, 1)\n",
      "gradient shape: (2, 1)\n",
      "(2, 3)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "import random, math\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def swish(x):\n",
    "    return x*sigmoid(x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def activation_function(z,act):\n",
    "    if act==\"sigmoid\":\n",
    "        return sigmoid(z)\n",
    "    elif act == \"swish\":\n",
    "        return swish(z)\n",
    "    elif act == \"relu\":\n",
    "        return relu(z)\n",
    "    elif act==\"tanh\":\n",
    "        return np.tanh(z)\n",
    "    \n",
    "class Layer():\n",
    "    def __init__(self,input_size,output_size,act=None):\n",
    "        self.size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.activation = act\n",
    "        self.weights = np.random.rand(self.output_size,self.size)*2-1      \n",
    "        self.bias = np.random.rand(output_size,1)*2-1\n",
    "        self.A = np.random.rand(output_size,1)*2-1\n",
    "        self.Z = np.random.rand(output_size,1)*2-1\n",
    "        \n",
    "    def forward_propagation(self, input_data):\n",
    "        self.Z = np.dot(self.weights,input_data)+self.bias\n",
    "        self.A = activation_function(self.Z, self.activation)\n",
    "        \n",
    "    def derMSE(self, target):\n",
    "        return 2*(self.A - target)\n",
    "    \n",
    "    def descent(self, input_data, gradient):\n",
    "        \n",
    "        derZ = 1 - np.power(self.A, 2)\n",
    "        \n",
    "        reps = (self.weights.shape[0], 1)\n",
    "        derWeights = np.tile(input_data.transpose(), reps)\n",
    "        print(input_data)\n",
    "        print(derWeights)\n",
    "        \"\"\"derWeights is a matrix with derivatives of Z WRT weights, which is transposed inputs, \n",
    "        repeated in rows n-times, where n is number of neurons.\n",
    "        \n",
    "    Example:\n",
    "    \n",
    "        input_data = [\n",
    "            [2],\n",
    "            [1],\n",
    "            [0]\n",
    "        ]\n",
    "        \n",
    "        derWeights = [\n",
    "            [2, 1, 0],\n",
    "            [2, 1, 0],\n",
    "            [2, 1, 0],\n",
    "            ... n-rows\n",
    "        ]\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"A shape: \" + str(self.A.shape))\n",
    "        print(\"gradient shape: \" + str(gradient.shape))\n",
    "        derBias = 1\n",
    "        wgrad = np.tile(np.multiply(gradient, derZ), (1, self.weights.shape[1]))\n",
    "        print(str(self.weights.shape))\n",
    "        derInputs = np.sum(wgrad, axis=0, keepdims=True)\n",
    "        print(str(derInputs.shape))\n",
    "        return derInputs.transpose()\n",
    "    \n",
    "    \"\"\" The above part adds the gradient to the derivative of Z WRT input_data and passes this new\n",
    "    gradient through return, to be used as the gradient for next layer's descent.\"\"\"\n",
    "        \n",
    "        \n",
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        self.layers=[]\n",
    "        self.epochs=10\n",
    "        self.learning_rate = 0.01\n",
    "    \n",
    "    def add_layer(self,input_size,output_size,activation=None):\n",
    "        new_layer = Layer(input_size,output_size,activation)\n",
    "        self.layers.append(new_layer)\n",
    "        \n",
    "    def forward_propagation(self,layer_no):\n",
    "        current_layer = self.layers[layer_no-1]\n",
    "        prev_layer = self.layers[layer_no-2]\n",
    "        act = current_layer.activation\n",
    "        input_data = prev_layer.A\n",
    "        self.Z = np.dot(weights,input_data)+self.bias\n",
    "        result = activation_function(self.Z,act)\n",
    "        current_layer.A = result\n",
    "        return result\n",
    "    \n",
    "    def full_forward_propagation(self, input_data):\n",
    "        self.layers[0].forward_propagation(input_data)\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i].forward_propagation(self.layers[i-1].A)\n",
    "        return self.layers[len(self.layers)-1].A\n",
    "    \n",
    "    def back_propagation(self, target):\n",
    "        gradient = self.layers[len(self.layers)-1].derMSE(target)\n",
    "        for i in range(0, len(self.layers)):\n",
    "            index = len(self.layers)-1 - i\n",
    "            print(\"Layer \" + str(index) + \" backpropagation\")\n",
    "            gradient = self.layers[index].descent(self.layers[index-1].A, gradient)\n",
    "\n",
    "\n",
    "test_data = np.array([\n",
    "    [3],\n",
    "    [2],\n",
    "    [1]\n",
    "])\n",
    "\n",
    "target_data = np.array([\n",
    "    [5],\n",
    "    [5],\n",
    "    [5]\n",
    "])\n",
    "\n",
    "network = NeuralNetwork()\n",
    "network.add_layer(3, 2, \"tanh\")\n",
    "network.add_layer(2, 3, \"swish\")\n",
    "\n",
    "network.full_forward_propagation(test_data)\n",
    "network.back_propagation(target_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
